{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolaGabriele/progettoDeepLearning/blob/main/ProgettoDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8qVmn0NluI3",
        "outputId": "7b76726a-1703-4086-8ccf-2d82e2e4b998"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "dW-CZdpb_BPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54836691-75d3-4a00-f16b-edc71d5c6daf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWHkUZ2-BrY",
        "outputId": "468a9fb1-b910-456a-c81f-07a201d5da83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is selected !\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models as resnet_model\n",
        "import torchvision\n",
        "import os\n",
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(str(device) + ' is selected !')\n",
        "\n",
        "IMAGES_DIR = '/content/drive/MyDrive/machinedeeplearning/BUS_UC/All/images'\n",
        "LABELS_DIR = '/content/drive/MyDrive/machinedeeplearning/BUS_UC/All/masks'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Dataset Loading***"
      ],
      "metadata": {
        "id": "RmdXcmqwlFSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, img_dir, lab_dir):\n",
        "    super(Dataset, self).__init__()\n",
        "    self.img_dir = img_dir\n",
        "    self.lab_dir = lab_dir\n",
        "    self.img_names = os.listdir(img_dir)\n",
        "    self.lab_names = os.listdir(lab_dir)\n",
        "    self.transform = torchvision.transforms.Resize((224,224))\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img_name = os.path.join(self.img_dir,self.img_names[idx])\n",
        "    mask_name = os.path.join(self.lab_dir, self.lab_names[idx])\n",
        "    image = torchvision.io.read_image(img_name)/255\n",
        "    image = self.transform(image)/255\n",
        "    mask = torchvision.io.read_image(mask_name)/255\n",
        "    mask = self.transform(mask)\n",
        "    return (image,mask[0])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(os.listdir(self.img_dir))"
      ],
      "metadata": {
        "id": "S7axHm52lJa0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = Dataset(IMAGES_DIR,LABELS_DIR)\n",
        "validationset, testset, trainset = random_split(data, [0.15,0.15,0.7])"
      ],
      "metadata": {
        "id": "aX_r9vP-MdPS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***MET-NET***"
      ],
      "metadata": {
        "id": "e6uPGnVVk8mM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBottleneckLayer(nn.Module):\n",
        "    def __init__(self, in_channels, n_filters, use_transpose=True):\n",
        "        super(DecoderBottleneckLayer, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "        if use_transpose:\n",
        "            self.up = nn.Sequential(\n",
        "                nn.ConvTranspose2d(\n",
        "                    in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1\n",
        "                ),\n",
        "                nn.BatchNorm2d(in_channels // 4),\n",
        "                nn.LeakyReLU()\n",
        "            )\n",
        "        else:\n",
        "            self.up = nn.Upsample(scale_factor=2, align_corners=True, mode=\"bilinear\")\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
        "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.up(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "\n",
        "class FFBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(FFBlock, self).__init__()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
        "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=1)\n",
        "\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x3 = self.conv3(x)\n",
        "        x3 = self.relu3(x3)\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.relu1(x1)\n",
        "        out = x3 + x1\n",
        "\n",
        "        return out\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, r=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // r, bias=False),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(channel // r, channel, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        ## Squeeze operation\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        ## Excitation operation\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        ## Fusion operation\n",
        "        y = torch.mul(x, y)\n",
        "        return y\n",
        "\n",
        "class PDFBlock(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels_list, kernel_size_list, dilation_list):\n",
        "        super(PDFBlock, self).__init__()\n",
        "        self.conv_num = len(out_channels_list)\n",
        "        assert(self.conv_num == 4)\n",
        "        assert(self.conv_num == len(kernel_size_list) and self.conv_num == len(dilation_list))\n",
        "        pad0 = int((kernel_size_list[0] - 1) / 2 * dilation_list[0])\n",
        "        pad1 = int((kernel_size_list[1] - 1) / 2 * dilation_list[1])\n",
        "        pad2 = int((kernel_size_list[2] - 1) / 2 * dilation_list[2])\n",
        "        pad3 = int((kernel_size_list[3] - 1) / 2 * dilation_list[3])\n",
        "        self.conv_1 = nn.Conv2d(in_channels, out_channels_list[0], kernel_size = kernel_size_list[0], dilation = dilation_list[0], padding = pad0 )\n",
        "        self.conv_2 = nn.Conv2d(in_channels, out_channels_list[1], kernel_size = kernel_size_list[1], dilation = dilation_list[1], padding = pad1 )\n",
        "        self.conv_3 = nn.Conv2d(in_channels, out_channels_list[2], kernel_size = kernel_size_list[2], dilation = dilation_list[2], padding = pad2 )\n",
        "        self.conv_4 = nn.Conv2d(in_channels, out_channels_list[3], kernel_size = kernel_size_list[3], dilation = dilation_list[3], padding = pad3 )\n",
        "\n",
        "        out_channels  = out_channels_list[0] + out_channels_list[1] + out_channels_list[2] + out_channels_list[3]\n",
        "        self.conv_1x1 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv_1(x)\n",
        "        x2 = self.conv_2(x)\n",
        "        x3 = self.conv_3(x)\n",
        "        x4 = self.conv_4(x)\n",
        "\n",
        "        y  = torch.cat([x1, x2, x3, x4], dim=1)\n",
        "        y  = self.conv_1x1(y)\n",
        "        return y\n",
        "\n",
        "class MET_Net(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1):\n",
        "        super(MET_Net, self).__init__()\n",
        "\n",
        "        transformer = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_distilled_patch16_224', pretrained=True)\n",
        "        resnet = resnet_model.resnet18(pretrained=True)\n",
        "\n",
        "        self.firstconv = resnet.conv1\n",
        "        self.firstbn = resnet.bn1\n",
        "        self.firstrelu = resnet.relu\n",
        "\n",
        "        self.encoder1 = resnet.layer1\n",
        "        self.encoder2 = resnet.layer2\n",
        "        self.encoder3 = resnet.layer3\n",
        "        self.encoder4 = resnet.layer4\n",
        "\n",
        "        self.patch_embed = transformer.patch_embed\n",
        "        self.transformers = nn.ModuleList( [transformer.blocks[i] for i in range(12)] )\n",
        "\n",
        "        self.conv_seq_img = nn.Conv2d(in_channels=192, out_channels=512, kernel_size=1, padding=0)\n",
        "        self.se = SEBlock(channel=1024)\n",
        "        self.conv2d = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, padding=0)\n",
        "\n",
        "        self.FFBlock1 = FFBlock(channels=64)\n",
        "        self.FFBlock2 = FFBlock(channels=128)\n",
        "        self.FFBlock3 = FFBlock(channels=256)\n",
        "\n",
        "        self.FFB1 = nn.ModuleList([self.FFBlock1 for i in range(6)])\n",
        "        self.FFB2 = nn.ModuleList([self.FFBlock2 for i in range(4)])\n",
        "        self.FFB3 = nn.ModuleList([self.FFBlock3 for i in range(2)])\n",
        "\n",
        "        filters = [64, 128, 256, 512]\n",
        "\n",
        "        self.decoder4 = DecoderBottleneckLayer(filters[3], filters[2])\n",
        "        self.decoder3 = DecoderBottleneckLayer(filters[2], filters[1])\n",
        "        self.decoder2 = DecoderBottleneckLayer(filters[1], filters[0])\n",
        "        self.decoder1 = DecoderBottleneckLayer(filters[0], filters[0])\n",
        "\n",
        "        self.final_conv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
        "        self.final_relu1 = nn.LeakyReLU()\n",
        "        self.final_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.final_relu2 = nn.LeakyReLU()\n",
        "        self.final_conv3 = nn.Conv2d(32, n_classes, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        e0 = self.firstconv(x)\n",
        "        e0 = self.firstbn(e0)\n",
        "        e0 = self.firstrelu(e0)\n",
        "\n",
        "        e1 = self.encoder1(e0)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        feature_cnn = self.encoder4(e3)\n",
        "\n",
        "        emb = self.patch_embed(x)\n",
        "        for i in range(12):\n",
        "            emb = self.transformers[i](emb)\n",
        "\n",
        "        feature_tf = emb.permute(0, 2, 1)\n",
        "        feature_tf = feature_tf.view(b, 192, 14, 14)\n",
        "        feature_tf = self.conv_seq_img(feature_tf)\n",
        "\n",
        "        feature_cat = torch.cat((feature_cnn, feature_tf), dim=1)\n",
        "        feature_att = self.se(feature_cat)\n",
        "        feature_out = self.conv2d(feature_att)\n",
        "\n",
        "        for i in range(2):\n",
        "            e3 = self.FFB3[i](e3)\n",
        "        for i in range(4):\n",
        "            e2 = self.FFB2[i](e2)\n",
        "        for i in range(6):\n",
        "            e1 = self.FFB1[i](e1)\n",
        "\n",
        "        d4 = self.decoder4(feature_out) + e3\n",
        "        d3 = self.decoder3(d4) + e2\n",
        "        d2 = self.decoder2(d3) + e1\n",
        "\n",
        "        out1 = self.final_conv1(d2)\n",
        "        out1 = self.final_relu1(out1)\n",
        "\n",
        "        out = self.final_conv2(out1)\n",
        "        out = self.final_relu2(out)\n",
        "        out = self.final_conv3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nkRyLfiO-Z6p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MET_Net()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESzgAzWE-eci",
        "outputId": "e689c444-d592-4804-f882-9b9d966a0476"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/deit/zipball/main\" to /root/.cache/torch/hub/main.zip\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:63: UserWarning: Overwriting deit_tiny_patch16_224 in registry with models.deit_tiny_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:78: UserWarning: Overwriting deit_small_patch16_224 in registry with models.deit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:93: UserWarning: Overwriting deit_base_patch16_224 in registry with models.deit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:108: UserWarning: Overwriting deit_tiny_distilled_patch16_224 in registry with models.deit_tiny_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_tiny_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:123: UserWarning: Overwriting deit_small_distilled_patch16_224 in registry with models.deit_small_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_small_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:138: UserWarning: Overwriting deit_base_distilled_patch16_224 in registry with models.deit_base_distilled_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_224(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:153: UserWarning: Overwriting deit_base_patch16_384 in registry with models.deit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_patch16_384(pretrained=False, **kwargs):\n",
            "/root/.cache/torch/hub/facebookresearch_deit_main/models.py:168: UserWarning: Overwriting deit_base_distilled_patch16_384 in registry with models.deit_base_distilled_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
            "  def deit_base_distilled_patch16_384(pretrained=False, **kwargs):\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_distilled_patch16_224-b40b3cf7.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_distilled_patch16_224-b40b3cf7.pth\n",
            "100%|██████████| 22.6M/22.6M [00:00<00:00, 164MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 188MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***Training***"
      ],
      "metadata": {
        "id": "PMfo2VGyGMp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DiceLoss,self).__init__()\n",
        "\n",
        "  def forward(self, predictions, targets):\n",
        "    pred = torch.nn.functional.sigmoid(predictions)\n",
        "    pred = torch.where(pred>=0.7, 1, 0).squeeze(dim=1)\n",
        "    targ = targets.squeeze(dim=1)\n",
        "    raps = np.zeros((pred.shape[0]))\n",
        "    for e in range(pred.shape[0]):\n",
        "      s1 = (targ[e]*pred[e]).flatten().sum()\n",
        "      s2 = pred[e].flatten().sum()\n",
        "      s3 = targ[e].flatten().sum()\n",
        "      rap = (1+2*s1)/(1+s3+s2)\n",
        "      raps[e] = rap\n",
        "    return torch.tensor(1-raps.mean(), requires_grad=True)"
      ],
      "metadata": {
        "id": "-7u2ANeWPWYh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iperparameters\n",
        "num_epochs = 100\n",
        "batch_size = 4\n",
        "learning_rate=1e-4\n",
        "optimizer = torch.optim.NAdam(params=model.parameters(),lr=learning_rate)\n",
        "lr = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,patience=15)\n",
        "dataloader = torch.utils.data.DataLoader(trainset,batch_size=batch_size,shuffle=True)\n",
        "loss_fn = DiceLoss()"
      ],
      "metadata": {
        "id": "Bxpm_bqzsRqC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(epoch_index):\n",
        "    l = []\n",
        "\n",
        "    for i, data in enumerate(dataloader):\n",
        "\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        l.append(loss.item())\n",
        "\n",
        "    print(f'Epoch {epoch_index} Loss (mean): {np.mean(l)}')"
      ],
      "metadata": {
        "id": "1YDMRd3pX-P-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "model.to('cuda')\n",
        "for epoch in range(1,num_epochs+1):\n",
        "  train_one_epoch(epoch)\n",
        "  if epoch%10 == 0:\n",
        "    torch.save(model,f'/content/drive/MyDrive/machinedeeplearning/models/model_{epoch}ep')"
      ],
      "metadata": {
        "id": "2rmulNuJZyU1",
        "outputId": "923a524d-b59b-40bd-e403-7ab5ade29a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss (mean): 0.9997390382170783\n",
            "Epoch 2 Loss (mean): 0.9997390371775299\n",
            "Epoch 3 Loss (mean): 0.9997390645588414\n",
            "Epoch 4 Loss (mean): 0.9997384471311044\n",
            "Epoch 5 Loss (mean): 0.9997391433276648\n",
            "Epoch 6 Loss (mean): 0.9997385691021362\n",
            "Epoch 7 Loss (mean): 0.9997384569591381\n",
            "Epoch 8 Loss (mean): 0.9997391397965344\n",
            "Epoch 9 Loss (mean): 0.9997391601789856\n",
            "Epoch 10 Loss (mean): 0.9997386007337878\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory /content/drive/MyDrive/machinedeeplearning/models does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-06fd39982829>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'/content/drive/MyDrive/machinedeeplearning/models/model_{epoch}ep'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_disable_byteorder_record\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory /content/drive/MyDrive/machinedeeplearning/models does not exist."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "train_one_epoch(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRkePmdAdGzS",
        "outputId": "6c3584ac-c150-458e-97ff-b441f3c96c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss (mean): 0.4986859874197548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = torch.randn((3,3,224,224))\n",
        "model.to('cpu')\n",
        "k = model(k)\n",
        "k = torch.nn.functional.sigmoid(k)\n",
        "k = torch.where(k>=0.6,1,0)\n",
        "l = torch.rand((3,1,224,224))\n",
        "l = torch.where(l>=0.6,1,0)\n",
        "loss_fn(k,l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIgcIm4fiFyR",
        "outputId": "da37be38-ca48-4b44-e7b2-db5b34fb4174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5891)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    }
  ]
}