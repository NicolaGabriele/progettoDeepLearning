{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI+CSh+ETwD/w4Bkvr2MEr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicolaGabriele/progettoDeepLearning/blob/main/ProgettoDeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awWHkUZ2-BrY",
        "outputId": "e081377a-9747-44c9-b0e6-47bef81c30f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu is selected !\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import f1_score\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models as resnet_model\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(str(device) + ' is selected !')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm"
      ],
      "metadata": {
        "id": "dW-CZdpb_BPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderBottleneckLayer(nn.Module):\n",
        "    def __init__(self, in_channels, n_filters, use_transpose=True):\n",
        "        super(DecoderBottleneckLayer, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, in_channels // 4, 1)\n",
        "        self.norm1 = nn.BatchNorm2d(in_channels // 4)\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "        if use_transpose:\n",
        "            self.up = nn.Sequential(\n",
        "                nn.ConvTranspose2d(\n",
        "                    in_channels // 4, in_channels // 4, 3, stride=2, padding=1, output_padding=1\n",
        "                ),\n",
        "                nn.BatchNorm2d(in_channels // 4),\n",
        "                nn.LeakyReLU()\n",
        "            )\n",
        "        else:\n",
        "            self.up = nn.Upsample(scale_factor=2, align_corners=True, mode=\"bilinear\")\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels // 4, n_filters, 1)\n",
        "        self.norm3 = nn.BatchNorm2d(n_filters)\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.up(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.relu3(x)\n",
        "        return x\n",
        "\n",
        "class FFBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(FFBlock, self).__init__()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=3, padding=1)\n",
        "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=1)\n",
        "\n",
        "        self.relu3 = nn.LeakyReLU()\n",
        "        self.relu1 = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x3 = self.conv3(x)\n",
        "        x3 = self.relu3(x3)\n",
        "        x1 = self.conv1(x)\n",
        "        x1 = self.relu1(x1)\n",
        "        out = x3 + x1\n",
        "\n",
        "        return out\n",
        "\n",
        "class SEBlock(nn.Module):\n",
        "    def __init__(self, channel, r=16):\n",
        "        super(SEBlock, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(channel, channel // r, bias=False),\n",
        "            nn.LeakyReLU(),\n",
        "            nn.Linear(channel // r, channel, bias=False),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, _, _ = x.size()\n",
        "        ## Squeeze operation\n",
        "        y = self.avg_pool(x).view(b, c)\n",
        "        ## Excitation operation\n",
        "        y = self.fc(y).view(b, c, 1, 1)\n",
        "        ## Fusion operation\n",
        "        y = torch.mul(x, y)\n",
        "        return y\n",
        "\n",
        "class PDFBlock(nn.Module):\n",
        "    def __init__(self,in_channels, out_channels_list, kernel_size_list, dilation_list):\n",
        "        super(PDFBlock, self).__init__()\n",
        "        self.conv_num = len(out_channels_list)\n",
        "        assert(self.conv_num == 4)\n",
        "        assert(self.conv_num == len(kernel_size_list) and self.conv_num == len(dilation_list))\n",
        "        pad0 = int((kernel_size_list[0] - 1) / 2 * dilation_list[0])\n",
        "        pad1 = int((kernel_size_list[1] - 1) / 2 * dilation_list[1])\n",
        "        pad2 = int((kernel_size_list[2] - 1) / 2 * dilation_list[2])\n",
        "        pad3 = int((kernel_size_list[3] - 1) / 2 * dilation_list[3])\n",
        "        self.conv_1 = nn.Conv2d(in_channels, out_channels_list[0], kernel_size = kernel_size_list[0], dilation = dilation_list[0], padding = pad0 )\n",
        "        self.conv_2 = nn.Conv2d(in_channels, out_channels_list[1], kernel_size = kernel_size_list[1], dilation = dilation_list[1], padding = pad1 )\n",
        "        self.conv_3 = nn.Conv2d(in_channels, out_channels_list[2], kernel_size = kernel_size_list[2], dilation = dilation_list[2], padding = pad2 )\n",
        "        self.conv_4 = nn.Conv2d(in_channels, out_channels_list[3], kernel_size = kernel_size_list[3], dilation = dilation_list[3], padding = pad3 )\n",
        "\n",
        "        out_channels  = out_channels_list[0] + out_channels_list[1] + out_channels_list[2] + out_channels_list[3]\n",
        "        self.conv_1x1 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv_1(x)\n",
        "        x2 = self.conv_2(x)\n",
        "        x3 = self.conv_3(x)\n",
        "        x4 = self.conv_4(x)\n",
        "\n",
        "        y  = torch.cat([x1, x2, x3, x4], dim=1)\n",
        "        y  = self.conv_1x1(y)\n",
        "        return y\n",
        "\n",
        "class MET_Net(nn.Module):\n",
        "    def __init__(self, n_channels=3, n_classes=1):\n",
        "        super(MET_Net, self).__init__()\n",
        "\n",
        "        transformer = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_distilled_patch16_224', pretrained=True)\n",
        "        resnet = resnet_model.resnet18(pretrained=True)\n",
        "\n",
        "        self.firstconv = resnet.conv1\n",
        "        self.firstbn = resnet.bn1\n",
        "        self.firstrelu = resnet.relu\n",
        "\n",
        "        self.encoder1 = resnet.layer1\n",
        "        self.encoder2 = resnet.layer2\n",
        "        self.encoder3 = resnet.layer3\n",
        "        self.encoder4 = resnet.layer4\n",
        "\n",
        "        self.patch_embed = transformer.patch_embed\n",
        "        self.transformers = nn.ModuleList( [transformer.blocks[i] for i in range(12)] )\n",
        "\n",
        "        self.conv_seq_img = nn.Conv2d(in_channels=192, out_channels=512, kernel_size=1, padding=0)\n",
        "        self.se = SEBlock(channel=1024)\n",
        "        self.conv2d = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, padding=0)\n",
        "\n",
        "        self.FFBlock1 = FFBlock(channels=64)\n",
        "        self.FFBlock2 = FFBlock(channels=128)\n",
        "        self.FFBlock3 = FFBlock(channels=256)\n",
        "\n",
        "        self.FFB1 = nn.ModuleList([self.FFBlock1 for i in range(6)])\n",
        "        self.FFB2 = nn.ModuleList([self.FFBlock2 for i in range(4)])\n",
        "        self.FFB3 = nn.ModuleList([self.FFBlock3 for i in range(2)])\n",
        "\n",
        "        filters = [64, 128, 256, 512]\n",
        "\n",
        "        self.decoder4 = DecoderBottleneckLayer(filters[3], filters[2])\n",
        "        self.decoder3 = DecoderBottleneckLayer(filters[2], filters[1])\n",
        "        self.decoder2 = DecoderBottleneckLayer(filters[1], filters[0])\n",
        "        self.decoder1 = DecoderBottleneckLayer(filters[0], filters[0])\n",
        "\n",
        "        self.final_conv1 = nn.ConvTranspose2d(filters[0], 32, 4, 2, 1)\n",
        "        self.final_relu1 = nn.LeakyReLU()\n",
        "        self.final_conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
        "        self.final_relu2 = nn.LeakyReLU()\n",
        "        self.final_conv3 = nn.Conv2d(32, n_classes, 3, padding=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "\n",
        "        e0 = self.firstconv(x)\n",
        "        e0 = self.firstbn(e0)\n",
        "        e0 = self.firstrelu(e0)\n",
        "\n",
        "        e1 = self.encoder1(e0)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        feature_cnn = self.encoder4(e3)\n",
        "\n",
        "        emb = self.patch_embed(x)\n",
        "        for i in range(12):\n",
        "            emb = self.transformers[i](emb)\n",
        "\n",
        "        feature_tf = emb.permute(0, 2, 1)\n",
        "        feature_tf = feature_tf.view(b, 192, 14, 14)\n",
        "        feature_tf = self.conv_seq_img(feature_tf)\n",
        "\n",
        "        feature_cat = torch.cat((feature_cnn, feature_tf), dim=1)\n",
        "        feature_att = self.se(feature_cat)\n",
        "        feature_out = self.conv2d(feature_att)\n",
        "\n",
        "        for i in range(2):\n",
        "            e3 = self.FFB3[i](e3)\n",
        "        for i in range(4):\n",
        "            e2 = self.FFB2[i](e2)\n",
        "        for i in range(6):\n",
        "            e1 = self.FFB1[i](e1)\n",
        "\n",
        "        d4 = self.decoder4(feature_out) + e3\n",
        "        d3 = self.decoder3(d4) + e2\n",
        "        d2 = self.decoder2(d3) + e1\n",
        "\n",
        "        out1 = self.final_conv1(d2)\n",
        "        out1 = self.final_relu1(out1)\n",
        "\n",
        "        out = self.final_conv2(out1)\n",
        "        out = self.final_relu2(out)\n",
        "        out = self.final_conv3(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "nkRyLfiO-Z6p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MET_Net()\n",
        "model.eval()\n",
        "t = torch.randn((1,3,224,224))\n",
        "k = model(t)[0][0].detach().numpy()\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESzgAzWE-eci",
        "outputId": "ce739339-c2d0-4d45-a223-4b68808517ac"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04425128, -0.04063698, -0.03882769, ..., -0.0394303 ,\n",
              "        -0.03862706, -0.03184101],\n",
              "       [-0.04228478, -0.05523727, -0.03340497, ..., -0.05538046,\n",
              "        -0.03668797, -0.03793998],\n",
              "       [-0.05114161, -0.05240801, -0.04430895, ..., -0.05321038,\n",
              "        -0.04164102, -0.03778284],\n",
              "       ...,\n",
              "       [-0.03716347, -0.05239111, -0.02903592, ..., -0.05694944,\n",
              "        -0.0302833 , -0.04431417],\n",
              "       [-0.04681999, -0.05842783, -0.04591626, ..., -0.05684927,\n",
              "        -0.04508224, -0.03451791],\n",
              "       [-0.02824719, -0.03192984, -0.02717286, ..., -0.03543681,\n",
              "        -0.02766658, -0.03049275]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}